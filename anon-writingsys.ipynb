{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "standard-aerospace",
   "metadata": {},
   "source": [
    "# Anonymizing languages' writing systems\n",
    "For each language's extracted text file (or more precisely a portion I have chosen for the train dataset), I compute how common each character is. The most common character corresponds to 0, second most common to 1 and so on. The space character is not transformed; it's still just space. Then, I replace the characters with their number correspondances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "limiting-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import sys # to get max int\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "purple-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = './data_chunked/'\n",
    "outpath = './data/chunks-anon/'\n",
    "files = ['en.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "consistent-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigns each character to a number. space is always 0. then, if the most common non-space\n",
    "# char is found to be 'e', then e gets assigned 1. if 't' is second most common, t is given 2.\n",
    "def make_transform(chunks):\n",
    "    char_dict = {}\n",
    "    char_dict[' '] = sys.maxsize\n",
    "    # index 0 is reserved character for space, corresponds to \"most common\"\n",
    "    \n",
    "    for s in chunks:\n",
    "        for c in s: # iterate over ea char in ea chunk\n",
    "            if c == ' ' or c == '\\n':\n",
    "                continue\n",
    "            char_dict[c] = char_dict.get(c, 0) + 1 # find num occurences of ea char\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(char_dict, orient='index', columns=['occur'])\n",
    "    df.sort_values(by='occur', inplace=True, ascending=False) # sort by num occurrences\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = ['char', 'occur']\n",
    "    df['ind'] = df.index # space will be index 0, most common char index 1, etc\n",
    "    df.set_index('char', inplace=True) # set index back to the characters\n",
    "    del df['occur'] # delete the num occurences\n",
    "    trans = df.to_dict()['ind'] # dict of char to word common-ness\n",
    "    return df, trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "afraid-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the supplied transformation, transform ea char in the text\n",
    "def apply_transform(chunks, trans):\n",
    "    chunks_trans = []\n",
    "    \n",
    "    for i,chunk in enumerate(chunks):\n",
    "        chunkarr = list(chunk)[:-1] # strip off newline \\n char at very end\n",
    "        for j,c in enumerate(chunkarr):\n",
    "            chunkarr[j] = trans[c]\n",
    "        chunks_trans.append(chunkarr)\n",
    "    \n",
    "    return chunks_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "nominated-cornell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaa.txt\n",
      "glk.txt\n",
      "el.txt\n",
      "gd.txt\n",
      "io.txt\n",
      "myv.txt\n",
      "sv.txt\n",
      "sa.txt\n",
      "sw.txt\n",
      "pl.txt\n",
      "mni.txt\n",
      "fa.txt\n",
      "bjn.txt\n",
      "eml.txt\n",
      "koi.txt\n",
      "kab.txt\n",
      "rue.txt\n",
      "eo.txt\n",
      "mzn.txt\n",
      "tcy.txt\n",
      "su.txt\n",
      "diq.txt\n",
      "sc.txt\n",
      "shn.txt\n",
      "azb.txt\n",
      "ang.txt\n",
      "ja.txt\n",
      "hi.txt\n",
      "jv.txt\n",
      "tyv.txt\n",
      "en.txt\n",
      "gor.txt\n",
      "gan.txt\n",
      "lez.txt\n",
      "lij.txt\n",
      "pag.txt\n",
      "pap.txt\n",
      "pms.txt\n",
      "mwl.txt\n",
      "gu.txt\n",
      "ka.txt\n",
      "kv.txt\n",
      "awa.txt\n",
      "sq.txt\n",
      "ru.txt\n",
      "kw.txt\n",
      "ace.txt\n",
      "nqo.txt\n",
      "ga.txt\n",
      "gv.txt\n",
      "fr.txt\n",
      "hy.txt\n",
      "ku.txt\n",
      "sd.txt\n",
      "skr.txt\n",
      "rw.txt\n",
      "sr.txt\n",
      "se.txt\n",
      "hsb.txt\n",
      "vls.txt\n",
      "xal.txt\n",
      "inh.txt\n",
      "udm.txt\n",
      "lad.txt\n",
      "krc.txt\n",
      "co.txt\n",
      "ms.txt\n",
      "zea.txt\n",
      "tg.txt\n",
      "jbo.txt\n",
      "vo.txt\n",
      "min.txt\n",
      "ceb.txt\n",
      "la.txt\n",
      "lv.txt\n",
      "om.txt\n",
      "mr.txt\n",
      "cy.txt\n",
      "af.txt\n",
      "nap.txt\n",
      "war.txt\n",
      "wuu.txt\n",
      "as.txt\n",
      "bh.txt\n",
      "lt.txt\n",
      "mg.txt\n",
      "sat.txt\n",
      "tr.txt\n",
      "te.txt\n",
      "ts.txt\n",
      "dty.txt\n",
      "lb.txt\n",
      "crh.txt\n",
      "ar.txt\n",
      "szl.txt\n",
      "av.txt\n",
      "ny.txt\n",
      "tpi.txt\n",
      "nn.txt\n",
      "scn.txt\n",
      "ary.txt\n",
      "hyw.txt\n",
      "ur.txt\n",
      "vi.txt\n",
      "ta.txt\n",
      "sco.txt\n",
      "stq.txt\n",
      "mt.txt\n",
      "no.txt\n",
      "lg.txt\n",
      "ban.txt\n",
      "ab.txt\n",
      "bn.txt\n",
      "zh.txt\n",
      "ug.txt\n",
      "arz.txt\n",
      "wo.txt\n",
      "tt.txt\n",
      "nl.txt\n",
      "bo.txt\n",
      "szy.txt\n",
      "README.md\n",
      "bug.txt\n",
      "an.txt\n",
      "ay.txt\n",
      "li.txt\n",
      "or.txt\n",
      "nv.txt\n",
      "uk.txt\n",
      "tn.txt\n",
      "yi.txt\n",
      "cdo.txt\n",
      "sah.txt\n",
      "ml.txt\n",
      "os.txt\n",
      "lmo.txt\n",
      "pfl.txt\n",
      "am.txt\n",
      "az.txt\n",
      "ba.txt\n",
      "ce.txt\n",
      "mn.txt\n",
      "my.txt\n",
      "tl.txt\n",
      "ckb.txt\n",
      "wa.txt\n",
      "hak.txt\n",
      "cs.txt\n",
      "vep.txt\n",
      "bcl.txt\n",
      "ksh.txt\n",
      "vec.txt\n",
      "mrj.txt\n",
      "bs.txt\n",
      "oc.txt\n",
      "mk.txt\n",
      "lo.txt\n",
      "zu.txt\n",
      "uz.txt\n",
      "ast.txt\n",
      "fur.txt\n",
      "th.txt\n",
      "mdf.txt\n",
      "yo.txt\n",
      "mhr.txt\n",
      "ln.txt\n",
      "cv.txt\n",
      "br.txt\n",
      "ca.txt\n",
      "be.txt\n",
      "nah.txt\n",
      "bar.txt\n",
      "nov.txt\n",
      "bxr.txt\n",
      "bg.txt\n",
      "csb.txt\n",
      "smn.txt\n",
      "tk.txt\n",
      "tet.txt\n",
      "xh.txt\n",
      "mi.txt\n",
      "ne.txt\n",
      "pdc.txt\n",
      "lbe.txt\n",
      "nrm.txt\n",
      "kbd.txt\n",
      "fi.txt\n",
      "dv.txt\n",
      "da.txt\n",
      "kn.txt\n",
      "hu.txt\n",
      "als.txt\n",
      "dsb.txt\n",
      "ky.txt\n",
      "sh.txt\n",
      "ps.txt\n",
      "si.txt\n",
      "frr.txt\n",
      "rm.txt\n",
      "avk.txt\n",
      "mnw.txt\n",
      "ig.txt\n",
      "ht.txt\n",
      "ko.txt\n",
      "gl.txt\n",
      "es.txt\n",
      "kbp.txt\n",
      "gom.txt\n",
      "gn.txt\n",
      "km.txt\n",
      "ha.txt\n",
      "ie.txt\n",
      "frp.txt\n",
      "sk.txt\n",
      "ro.txt\n",
      "qu.txt\n",
      "id.txt\n",
      "is.txt\n",
      "gag.txt\n",
      "ilo.txt\n",
      "simple.txt\n",
      "nso.txt\n",
      "ext.txt\n",
      "bpy.txt\n",
      "et.txt\n",
      "fo.txt\n",
      "sn.txt\n",
      "pt.txt\n",
      "so.txt\n",
      "mai.txt\n",
      "hr.txt\n",
      "ia.txt\n",
      "he.txt\n",
      "eu.txt\n",
      "hif.txt\n",
      "fy.txt\n",
      "pam.txt\n",
      "pnb.txt\n",
      "it.txt\n",
      "kk.txt\n",
      "pa.txt\n",
      "sl.txt\n",
      "xmf.txt\n",
      "de.txt\n",
      "olo.txt\n",
      "new.txt\n",
      "nds.txt\n",
      "pcd.txt\n",
      "lfn.txt\n"
     ]
    }
   ],
   "source": [
    "# iterate over ea lang, make and apply transform, save to file\n",
    "for f in os.listdir(inpath):\n",
    "    if f == 'README.md' or f.startswith('.'): continue\n",
    "    print(f)\n",
    "    file = open(inpath+f, 'r')\n",
    "    chunks = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    df, trans = make_transform(chunks)\n",
    "    chunks_trans = apply_transform(chunks, trans)\n",
    "    \n",
    "    file = open(outpath+f, 'wb')\n",
    "    pickle.dump(chunks_trans, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-economics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
